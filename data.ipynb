{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "\n",
    "letter_list = list(alphabet)\n",
    "letter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_template = 'https://www.pro-football-reference.com/players/{}/'\n",
    "\n",
    "def get_WR(letter):\n",
    "    url = url_template.format(letter) # This formats the url by letter\n",
    "\n",
    "    response = requests.get(url)\n",
    "    time.sleep(8)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    players = []\n",
    "    div_players = soup.find('div', class_=\"section_content\", id=\"div_players\")\n",
    "    \n",
    "    # Loop through p tags\n",
    "    for p in div_players.find_all('p'):\n",
    "        meta = p.get_text()\n",
    "        position = str(meta.split('(')[1].split(')')[0])\n",
    "        is_wr = 1 if 'WR' in position else 0\n",
    "        year_span = meta.split(')')[1].strip()\n",
    "        start_year = int(year_span.split('-')[0])\n",
    "        hyper_link = p.find('a')['href']\n",
    "        player_link = f'https://www.pro-football-reference.com{hyper_link}'\n",
    "        if is_wr == 1 and start_year >= 2018:\n",
    "            players.append([meta, position, year_span, player_link])\n",
    "    df = pd.DataFrame(players, columns = ['meta', 'position', 'year_span', 'player_link'])\n",
    "    return df \n",
    "\n",
    "all_players = pd.concat([get_WR(letter) for letter in letter_list], ignore_index=True)\n",
    "all_players.to_csv(\"wide_receiver_links.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error for player at index 0: 'NoneType' object has no attribute 'a'\n",
      "Error for player at index 1: 'NoneType' object has no attribute 'a'\n",
      "Error for player at index 1: 'NoneType' object has no attribute 'a'\n",
      "Error for player at index 1: 'NoneType' object has no attribute 'a'\n",
      "Error for player at index 1: 'NoneType' object has no attribute 'a'\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/eddie/Desktop/Sports Analytics/Wr_Grades/data.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eddie/Desktop/Sports%20Analytics/Wr_Grades/data.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eddie/Desktop/Sports%20Analytics/Wr_Grades/data.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(player_link)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/eddie/Desktop/Sports%20Analytics/Wr_Grades/data.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     time\u001b[39m.\u001b[39msleep(\u001b[39m8\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eddie/Desktop/Sports%20Analytics/Wr_Grades/data.ipynb#W5sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(response\u001b[39m.\u001b[39mtext, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/eddie/Desktop/Sports%20Analytics/Wr_Grades/data.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     table \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39mtable\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the output folder\n",
    "output_folder = 'Wr_Players'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Load the CSV with player links\n",
    "wr = pd.read_csv('wide_receiver_links.csv')\n",
    "\n",
    "# Scrape the tables off the player links\n",
    "for index, player_link in enumerate(wr['player_link']):\n",
    "    try:\n",
    "        response = requests.get(player_link)\n",
    "        time.sleep(8)\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        table = soup.find_all('table')[0]\n",
    "\n",
    "        reg_df = []\n",
    "\n",
    "        for i, row in enumerate(table.find_all('tr')[2:]):\n",
    "            try:\n",
    "                player_info = row.find('td', attrs={'data-stat': 'player'})\n",
    "                name = player_info.a.get_text()\n",
    "                position = 'WR'\n",
    "\n",
    "                # Grab the player stats\n",
    "                tdf = pd.read_html(player_link)[0]\n",
    "\n",
    "                # Get rid of MultiIndex, keep last row\n",
    "                tdf.columns = tdf.columns.get_level_values(-1)\n",
    "\n",
    "                # Drop unnecessary columns\n",
    "                tdf = tdf.iloc[:, [1, 3, 4] + list(range(19, tdf.shape[1]))]\n",
    "\n",
    "                # Add other info\n",
    "                tdf['Name'] = name\n",
    "                tdf['Position'] = position\n",
    "\n",
    "                # Append the DataFrame to reg_df\n",
    "                reg_df.append(tdf)\n",
    "\n",
    "                # Create and save an individual CSV file for the player\n",
    "                file_path = os.path.join(output_folder, f'{name}.csv')\n",
    "                tdf.to_csv(file_path, index=False)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error for player at index {index}: {str(e)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error for player at index {index}: {str(e)}\")\n",
    "\n",
    "# Concatenate all player DataFrames into one DataFrame if needed\n",
    "if reg_df:\n",
    "    reg_df = pd.concat(reg_df, ignore_index=True)\n",
    "    reg_df.head()\n",
    "\n",
    "print(\"Scraping and CSV file creation completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
